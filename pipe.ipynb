{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=\"C:\\\\dev\\\\telstra\\\\data\\\\\"\n",
    "\n",
    "trainFile=\"train.csv\"\n",
    "testFile=\"test.csv\"\n",
    "resourceFile=\"resource_type.csv\"\n",
    "eventTypeFile=\"event_type.csv\"\n",
    "logFeatureFile=\"log_feature.csv\"\n",
    "severityTypeFile=\"severity_type.csv\"\n",
    "\n",
    "test=pd.read_csv(filepath_or_buffer=path+testFile,delimiter=\",\",header=0)\n",
    "train=pd.read_csv(filepath_or_buffer=path+trainFile,delimiter=\",\",header=0)\n",
    "\n",
    "resource=pd.read_csv(filepath_or_buffer=path+resourceFile,delimiter=\",\",header=0)\n",
    "event=pd.read_csv(filepath_or_buffer=path+eventTypeFile,delimiter=\",\",header=0)\n",
    "feature=pd.read_csv(filepath_or_buffer=path+logFeatureFile,delimiter=\",\",header=0)\n",
    "severity=pd.read_csv(filepath_or_buffer=path+severityTypeFile,delimiter=\",\",header=0)\n",
    "join=pd.DataFrame({'id':[]})\n",
    "datasets={'train':train,'test':test,'resource':resource,'event':event,'feature':feature,'severity':severity}\n",
    "notCat=['id','volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: feature\n",
      "Finished creating dummies\n",
      "Dataset: test\n",
      "Finished creating dummies\n",
      "Dataset: severity\n",
      "Finished creating dummies\n",
      "Dataset: event\n",
      "Finished creating dummies\n",
      "Dataset: train\n",
      "Finished creating dummies\n",
      "Dataset: resource\n",
      "Finished creating dummies\n"
     ]
    }
   ],
   "source": [
    "#convert table of ids and classes to binary row feature vectors for each unique id\n",
    "#takes a long time, thus once computed save results to csv file\n",
    "for key, dataset in datasets.items():\n",
    "    print('Dataset: '+key)\n",
    "    tmp=pd.get_dummies(dataset)\n",
    "    print('Finished creating dummies')\n",
    "    tmp=tmp.groupby('id').sum()\n",
    "    tmp['id']=tmp.index\n",
    "    dataset=tmp\n",
    "    datasets[key]=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates join dataset table that will store features for train and test datasets\n",
    "datasets['train']['sample']='train'\n",
    "datasets['test']['sample']='test'\n",
    "datasets['test']['fault_severity']=np.nan\n",
    "join=pd.concat([datasets['train'],datasets['test']],ignore_index=True)\n",
    "#join=join.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#joins features from different datasets into one dataframe, features only for evaluated ids are extracted\n",
    "#(i.e. some features may be not related to any id)\n",
    "samples=['train','test']\n",
    "for key, dataset in datasets.items():\n",
    "    if key not in samples:\n",
    "        join=pd.merge(join,dataset,on='id',how='left') #can use concat?\n",
    "\n",
    "join=join.set_index(['sample',join.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join=join.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of Random Forest: 0.5875897574854356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "features=join.columns.values\n",
    "features=features[2:]\n",
    "\n",
    "train_features = join.loc['train'][features]\n",
    "train_target = join.loc['train']['fault_severity']\n",
    "\n",
    "test_features = join.loc['test'][features]\n",
    "\n",
    "#Use csc_matrix?\n",
    "\n",
    "# Fit the model to training data\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = LinearSVC()\n",
    "#clf = MultinomialNB()\n",
    "clf = clf.fit(train_features, train_target)\n",
    "\n",
    "score = clf.score(train_features, train_target)\n",
    "print(\"Mean accuracy of Random Forest: {0}\".format(score))\n",
    "\n",
    "test_response=clf.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss = 2.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split 69-31 train vs test data\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_features, train_target, test_size=0.31, random_state=0)\n",
    "\n",
    "clf = clf.fit(train_x, train_y)\n",
    "predict_y = clf.predict_proba(test_x)\n",
    "\n",
    "print (\"LogLoss = %.2f\" % (log_loss(test_y, predict_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save predictions to required format\n",
    "out=pd.DataFrame({'id':[],'predict_0':[],'predict_1':[],'predict_2':[]})\n",
    "out['id']=test['id']\n",
    "out['predict_0']=test_response.T[0]\n",
    "out['predict_1']=test_response.T[1]\n",
    "out['predict_2']=test_response.T[2]\n",
    "out=out[['id','predict_0','predict_1','predict_2']]\n",
    "meanOut.to_csv('predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
