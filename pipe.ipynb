{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time as t\n",
    "from sklearn import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import import_datasets as imp\n",
    "\n",
    "datasets=imp.importData()\n",
    "\n",
    "notCat=['id','volume']\n",
    "cat_cols=['location','log_feature','severity_type','resource_type','event_type']\n",
    "samples=['train','test']\n",
    "\n",
    "join=pd.DataFrame({'id':[]})\n",
    "datasets['train']['sample']='train'\n",
    "datasets['test']['sample']='test'\n",
    "datasets['test']['fault_severity']=np.nan\n",
    "join=pd.concat([datasets['train'],datasets['test']],ignore_index=True)\n",
    "\n",
    "datasets['feature']['volume']=pd.cut(datasets['feature']['volume'],bins=[0,1,2,7,1310],\\\n",
    "                                     labels=[1,2,3,4]).astype(str)\n",
    "for key, dataset in datasets.items():\n",
    "    if key not in samples:\n",
    "        join=pd.merge(join,dataset,on='id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>sample</th>\n",
       "      <th>log_feature</th>\n",
       "      <th>volume</th>\n",
       "      <th>severity_type</th>\n",
       "      <th>event_type</th>\n",
       "      <th>resource_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 35</td>\n",
       "      <td>resource_type 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 232</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 232</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 35</td>\n",
       "      <td>resource_type 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9320</td>\n",
       "      <td>location 91</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 315</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fault_severity     id      location sample  log_feature volume  \\\n",
       "0               1  14121  location 118  train  feature 312      4   \n",
       "1               1  14121  location 118  train  feature 312      4   \n",
       "2               1  14121  location 118  train  feature 232      4   \n",
       "3               1  14121  location 118  train  feature 232      4   \n",
       "4               0   9320   location 91  train  feature 315      4   \n",
       "\n",
       "     severity_type     event_type    resource_type  \n",
       "0  severity_type 2  event_type 34  resource_type 2  \n",
       "1  severity_type 2  event_type 35  resource_type 2  \n",
       "2  severity_type 2  event_type 34  resource_type 2  \n",
       "3  severity_type 2  event_type 35  resource_type 2  \n",
       "4  severity_type 2  event_type 34  resource_type 2  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "dict_stats={}\n",
    "for column in cat_cols:\n",
    "    df=pd.crosstab(join[column],join['fault_severity'])\n",
    "    df[column+'_sum']=(df.sum(axis=1))\n",
    "    df.columns=['0','1','2',column+'_sum']\n",
    "    df[column+'_std']=df[['0','1','2']].std(axis=1)\n",
    "    f,_=chisquare(df[['0','1','2']],axis=1)\n",
    "    df[column+'_pchisqr']=f\n",
    "    \n",
    "    fs=[column+'_sum',column+'_std',column+'_pchisqr']\n",
    "    df=df[fs]\n",
    "    df[column]=df.index\n",
    "    dict_stats[column]=df\n",
    "    join=pd.merge(join,df,on=column,how=\"left\") #safer than inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event_type':                event_type_sum  event_type_std  event_type_pchisqr  \\\n",
       " event_type                                                          \n",
       " event_type 1                6        3.464102           12.000000   \n",
       " event_type 10             573       81.061705           68.806283   \n",
       " event_type 11           13125     1815.580348         1506.894629   \n",
       " event_type 12              14        5.686241           13.857143   \n",
       " event_type 13            2426      250.042663          154.628195   \n",
       " event_type 14            1809      102.941731           35.147595   \n",
       " event_type 15            5475      274.858145           82.791233   \n",
       " event_type 18             437       99.057223          134.723112   \n",
       " event_type 19              98       56.580326          196.000000   \n",
       " event_type 2               95       26.839026           45.494737   \n",
       " event_type 20            3404      711.174615          891.485311   \n",
       " event_type 21             359      111.545208          207.949861   \n",
       " event_type 22            1366       82.099533           29.606149   \n",
       " event_type 23            2055      395.548986          456.814599   \n",
       " event_type 24             170       40.066611           56.658824   \n",
       " event_type 25               8        4.618802           16.000000   \n",
       " event_type 26             195       88.662281          241.876923   \n",
       " event_type 27             199       10.969655            3.628141   \n",
       " event_type 28             224       70.500591          133.133929   \n",
       " event_type 29             134       43.546910           84.910448   \n",
       " event_type 3               72       24.000000           48.000000   \n",
       " event_type 30             173       54.372174          102.531792   \n",
       " event_type 31              15        4.582576            8.400000   \n",
       " event_type 32             104       16.653328           16.000000   \n",
       " event_type 34           11390     5142.110980        13928.694644   \n",
       " event_type 35           11989     5433.055341        14772.586704   \n",
       " event_type 36             159       60.555759          138.377358   \n",
       " event_type 37              13        7.505553           26.000000   \n",
       " event_type 38              50       12.055428           17.440000   \n",
       " event_type 39             100       40.414519           98.000000   \n",
       " event_type 40             124       44.241760           94.709677   \n",
       " event_type 41               9        5.196152           18.000000   \n",
       " event_type 42             967      119.215491           88.184074   \n",
       " event_type 43             756      116.511802          107.738095   \n",
       " event_type 44             957      115.052162           82.990596   \n",
       " event_type 45             159       20.074860           15.207547   \n",
       " event_type 46              79       12.662280           12.177215   \n",
       " event_type 47             130       17.953644           14.876923   \n",
       " event_type 48              15        8.660254           30.000000   \n",
       " event_type 49              65       25.658007           60.769231   \n",
       " event_type 5              234       35.594943           32.487179   \n",
       " event_type 50             233        7.505553            1.450644   \n",
       " event_type 51               8        4.618802           16.000000   \n",
       " event_type 53              50       28.867513          100.000000   \n",
       " event_type 54            1363      130.768243           75.276596   \n",
       " event_type 6              199       14.433757            6.281407   \n",
       " event_type 7              169       25.540817           23.159763   \n",
       " event_type 8               50        8.082904            7.840000   \n",
       " event_type 9               35       10.692677           19.600000   \n",
       " \n",
       "                   event_type  \n",
       " event_type                    \n",
       " event_type 1    event_type 1  \n",
       " event_type 10  event_type 10  \n",
       " event_type 11  event_type 11  \n",
       " event_type 12  event_type 12  \n",
       " event_type 13  event_type 13  \n",
       " event_type 14  event_type 14  \n",
       " event_type 15  event_type 15  \n",
       " event_type 18  event_type 18  \n",
       " event_type 19  event_type 19  \n",
       " event_type 2    event_type 2  \n",
       " event_type 20  event_type 20  \n",
       " event_type 21  event_type 21  \n",
       " event_type 22  event_type 22  \n",
       " event_type 23  event_type 23  \n",
       " event_type 24  event_type 24  \n",
       " event_type 25  event_type 25  \n",
       " event_type 26  event_type 26  \n",
       " event_type 27  event_type 27  \n",
       " event_type 28  event_type 28  \n",
       " event_type 29  event_type 29  \n",
       " event_type 3    event_type 3  \n",
       " event_type 30  event_type 30  \n",
       " event_type 31  event_type 31  \n",
       " event_type 32  event_type 32  \n",
       " event_type 34  event_type 34  \n",
       " event_type 35  event_type 35  \n",
       " event_type 36  event_type 36  \n",
       " event_type 37  event_type 37  \n",
       " event_type 38  event_type 38  \n",
       " event_type 39  event_type 39  \n",
       " event_type 40  event_type 40  \n",
       " event_type 41  event_type 41  \n",
       " event_type 42  event_type 42  \n",
       " event_type 43  event_type 43  \n",
       " event_type 44  event_type 44  \n",
       " event_type 45  event_type 45  \n",
       " event_type 46  event_type 46  \n",
       " event_type 47  event_type 47  \n",
       " event_type 48  event_type 48  \n",
       " event_type 49  event_type 49  \n",
       " event_type 5    event_type 5  \n",
       " event_type 50  event_type 50  \n",
       " event_type 51  event_type 51  \n",
       " event_type 53  event_type 53  \n",
       " event_type 54  event_type 54  \n",
       " event_type 6    event_type 6  \n",
       " event_type 7    event_type 7  \n",
       " event_type 8    event_type 8  \n",
       " event_type 9    event_type 9  ,\n",
       " 'location':                location_sum  location_std  location_pchisqr       location\n",
       " location                                                                  \n",
       " location 1              163     35.949038         47.570552     location 1\n",
       " location 10               2      1.154701          4.000000    location 10\n",
       " location 100             96     51.156622        163.562500   location 100\n",
       " location 1000            29     16.743158         58.000000  location 1000\n",
       " location 1002             2      1.154701          4.000000  location 1002\n",
       " location 1005             2      1.154701          4.000000  location 1005\n",
       " location 1006             4      2.309401          8.000000  location 1006\n",
       " location 1007            62     26.102363         65.935484  location 1007\n",
       " location 1008           279     39.686270         33.870968  location 1008\n",
       " location 1009             5      2.886751         10.000000  location 1009\n",
       " location 101             12      6.928203         24.000000   location 101\n",
       " location 1010            40     13.503086         27.350000  location 1010\n",
       " location 1011            17      6.350853         14.235294  location 1011\n",
       " location 1013            24     13.856406         48.000000  location 1013\n",
       " location 1014           207     39.230090         44.608696  location 1014\n",
       " location 1015            19      6.027714         11.473684  location 1015\n",
       " location 1016             6      2.000000          4.000000  location 1016\n",
       " location 1017            19      5.033223          8.000000  location 1017\n",
       " location 1018           113     37.501111         74.672566  location 1018\n",
       " location 1019           285     63.505905         84.905263  location 1019\n",
       " location 102            665    306.160633        845.723308   location 102\n",
       " location 1020            45     20.223748         54.533333  location 1020\n",
       " location 1021            18      6.000000         12.000000  location 1021\n",
       " location 1022             3      1.000000          2.000000  location 1022\n",
       " location 1023            26     10.263203         24.307692  location 1023\n",
       " location 1024            36     19.078784         60.666667  location 1024\n",
       " location 1025            20      5.773503         10.000000  location 1025\n",
       " location 1026           198     35.763109         38.757576  location 1026\n",
       " location 1027             1      0.577350          2.000000  location 1027\n",
       " location 1029             5      2.886751         10.000000  location 1029\n",
       " ...                     ...           ...               ...            ...\n",
       " location 963             36     20.784610         72.000000   location 963\n",
       " location 964              7      2.516611          5.428571   location 964\n",
       " location 966              2      1.154701          4.000000   location 966\n",
       " location 967             45     23.388031         72.933333   location 967\n",
       " location 968              2      1.154701          4.000000   location 968\n",
       " location 969              2      1.154701          4.000000   location 969\n",
       " location 97              35     10.408330         18.571429    location 97\n",
       " location 971              1      0.577350          2.000000   location 971\n",
       " location 972             82     35.345910         91.414634   location 972\n",
       " location 973              3      1.732051          6.000000   location 973\n",
       " location 974             10      0.577350          0.200000   location 974\n",
       " location 975              4      2.309401          8.000000   location 975\n",
       " location 976            199      8.386497          2.120603   location 976\n",
       " location 977             95     27.790886         48.778947   location 977\n",
       " location 978             37     18.009257         52.594595   location 978\n",
       " location 979             18      5.291503          9.333333   location 979\n",
       " location 980              6      2.000000          4.000000   location 980\n",
       " location 981              4      1.154701          2.000000   location 981\n",
       " location 983             12      4.582576         10.500000   location 983\n",
       " location 984            437    108.075591        160.370709   location 984\n",
       " location 987              2      1.154701          4.000000   location 987\n",
       " location 989             33     11.269428         23.090909   location 989\n",
       " location 99              13      7.505553         26.000000    location 99\n",
       " location 990             11      3.214550          5.636364   location 990\n",
       " location 991             15      6.244998         15.600000   location 991\n",
       " location 994              8      4.618802         16.000000   location 994\n",
       " location 995            378    118.114351        221.444444   location 995\n",
       " location 996              6      2.645751          7.000000   location 996\n",
       " location 998             24      7.000000         12.250000   location 998\n",
       " location 999              9      2.645751          4.666667   location 999\n",
       " \n",
       " [929 rows x 4 columns],\n",
       " 'log_feature':              log_feature_sum  log_feature_std  log_feature_pchisqr  \\\n",
       " log_feature                                                          \n",
       " feature 1                 28         4.163332             3.714286   \n",
       " feature 10                44        18.175075            45.045455   \n",
       " feature 101               15         7.810250            24.400000   \n",
       " feature 103               20         3.785939             4.300000   \n",
       " feature 104                9         5.196152            18.000000   \n",
       " feature 105               22         7.023769            13.454545   \n",
       " feature 106                3         1.732051             6.000000   \n",
       " feature 107                2         1.154701             4.000000   \n",
       " feature 108               18         6.000000            12.000000   \n",
       " feature 109               27        15.588457            54.000000   \n",
       " feature 11                 9         5.196152            18.000000   \n",
       " feature 110                6         3.464102            12.000000   \n",
       " feature 111               36        11.135529            20.666667   \n",
       " feature 112                2         1.154701             4.000000   \n",
       " feature 113                6         3.464102            12.000000   \n",
       " feature 114               34         9.865766            17.176471   \n",
       " feature 115               12         3.464102             6.000000   \n",
       " feature 117               58        20.033306            41.517241   \n",
       " feature 118              120        23.065125            26.600000   \n",
       " feature 12                 9         5.196152            18.000000   \n",
       " feature 120               17         6.658328            15.647059   \n",
       " feature 122               11         6.350853            22.000000   \n",
       " feature 123                8         4.618802            16.000000   \n",
       " feature 124                7         2.081666             3.714286   \n",
       " feature 125               19         7.767453            19.052632   \n",
       " feature 127               91        24.006943            38.000000   \n",
       " feature 128               30        17.320508            60.000000   \n",
       " feature 13                16         9.237604            32.000000   \n",
       " feature 130                1         0.577350             2.000000   \n",
       " feature 131                1         0.577350             2.000000   \n",
       " ...                      ...              ...                  ...   \n",
       " feature 70               177        84.005952           239.220339   \n",
       " feature 71              1423       175.972536           130.567814   \n",
       " feature 73               359       182.653588           557.587744   \n",
       " feature 74               132        18.193405            15.045455   \n",
       " feature 75               518       149.694133           259.555985   \n",
       " feature 76                63         6.082763             3.523810   \n",
       " feature 77                 2         1.154701             4.000000   \n",
       " feature 78                29         8.736895            15.793103   \n",
       " feature 79                 2         0.577350             1.000000   \n",
       " feature 8                117        10.816654             6.000000   \n",
       " feature 80              1043        75.035547            32.389262   \n",
       " feature 81               150        37.589892            56.520000   \n",
       " feature 82              2359       128.850042            42.227215   \n",
       " feature 83                31         3.055050             1.806452   \n",
       " feature 84                12         2.645751             3.500000   \n",
       " feature 85                32         9.609024            17.312500   \n",
       " feature 86                26        10.969655            27.769231   \n",
       " feature 87               170        26.312228            24.435294   \n",
       " feature 88                25         8.020806            15.440000   \n",
       " feature 89                25         8.020806            15.440000   \n",
       " feature 9                  4         2.309401             8.000000   \n",
       " feature 90                25         8.020806            15.440000   \n",
       " feature 91                25         8.020806            15.440000   \n",
       " feature 92                25         8.020806            15.440000   \n",
       " feature 94               313        88.081402           148.722045   \n",
       " feature 95                67        19.502137            34.059701   \n",
       " feature 96                 4         2.309401             8.000000   \n",
       " feature 97                 8         4.618802            16.000000   \n",
       " feature 98                15         7.810250            24.400000   \n",
       " feature 99                 9         4.358899            12.666667   \n",
       " \n",
       "              log_feature  \n",
       " log_feature               \n",
       " feature 1      feature 1  \n",
       " feature 10    feature 10  \n",
       " feature 101  feature 101  \n",
       " feature 103  feature 103  \n",
       " feature 104  feature 104  \n",
       " feature 105  feature 105  \n",
       " feature 106  feature 106  \n",
       " feature 107  feature 107  \n",
       " feature 108  feature 108  \n",
       " feature 109  feature 109  \n",
       " feature 11    feature 11  \n",
       " feature 110  feature 110  \n",
       " feature 111  feature 111  \n",
       " feature 112  feature 112  \n",
       " feature 113  feature 113  \n",
       " feature 114  feature 114  \n",
       " feature 115  feature 115  \n",
       " feature 117  feature 117  \n",
       " feature 118  feature 118  \n",
       " feature 12    feature 12  \n",
       " feature 120  feature 120  \n",
       " feature 122  feature 122  \n",
       " feature 123  feature 123  \n",
       " feature 124  feature 124  \n",
       " feature 125  feature 125  \n",
       " feature 127  feature 127  \n",
       " feature 128  feature 128  \n",
       " feature 13    feature 13  \n",
       " feature 130  feature 130  \n",
       " feature 131  feature 131  \n",
       " ...                  ...  \n",
       " feature 70    feature 70  \n",
       " feature 71    feature 71  \n",
       " feature 73    feature 73  \n",
       " feature 74    feature 74  \n",
       " feature 75    feature 75  \n",
       " feature 76    feature 76  \n",
       " feature 77    feature 77  \n",
       " feature 78    feature 78  \n",
       " feature 79    feature 79  \n",
       " feature 8      feature 8  \n",
       " feature 80    feature 80  \n",
       " feature 81    feature 81  \n",
       " feature 82    feature 82  \n",
       " feature 83    feature 83  \n",
       " feature 84    feature 84  \n",
       " feature 85    feature 85  \n",
       " feature 86    feature 86  \n",
       " feature 87    feature 87  \n",
       " feature 88    feature 88  \n",
       " feature 89    feature 89  \n",
       " feature 9      feature 9  \n",
       " feature 90    feature 90  \n",
       " feature 91    feature 91  \n",
       " feature 92    feature 92  \n",
       " feature 94    feature 94  \n",
       " feature 95    feature 95  \n",
       " feature 96    feature 96  \n",
       " feature 97    feature 97  \n",
       " feature 98    feature 98  \n",
       " feature 99    feature 99  \n",
       " \n",
       " [331 rows x 4 columns],\n",
       " 'resource_type':                   resource_type_sum  resource_type_std  resource_type_pchisqr  \\\n",
       " resource_type                                                                   \n",
       " resource_type 1                 647          53.799009              26.840804   \n",
       " resource_type 10                451          92.856520             114.709534   \n",
       " resource_type 2               31746       11667.207935           25727.412776   \n",
       " resource_type 3                 724         116.362938             112.212707   \n",
       " resource_type 4                1925         116.603316              42.378182   \n",
       " resource_type 5                 119          68.704682             238.000000   \n",
       " resource_type 6                2511         247.574231             146.458781   \n",
       " resource_type 7                2900         430.127113             382.777931   \n",
       " resource_type 8               20005        2175.155703            1419.035941   \n",
       " resource_type 9                 811         151.242631             169.230580   \n",
       " \n",
       "                      resource_type  \n",
       " resource_type                       \n",
       " resource_type 1    resource_type 1  \n",
       " resource_type 10  resource_type 10  \n",
       " resource_type 2    resource_type 2  \n",
       " resource_type 3    resource_type 3  \n",
       " resource_type 4    resource_type 4  \n",
       " resource_type 5    resource_type 5  \n",
       " resource_type 6    resource_type 6  \n",
       " resource_type 7    resource_type 7  \n",
       " resource_type 8    resource_type 8  \n",
       " resource_type 9    resource_type 9  ,\n",
       " 'severity_type':                  severity_type_sum  severity_type_std  severity_type_pchisqr  \\\n",
       " severity_type                                                                  \n",
       " severity_type 1              36571        4211.818649            2910.407099   \n",
       " severity_type 2              24260        9922.367728           24349.558450   \n",
       " severity_type 3                 33          19.052559              66.000000   \n",
       " severity_type 4                920         335.497144             734.076087   \n",
       " severity_type 5                 55          18.009257              35.381818   \n",
       " \n",
       "                    severity_type  \n",
       " severity_type                     \n",
       " severity_type 1  severity_type 1  \n",
       " severity_type 2  severity_type 2  \n",
       " severity_type 3  severity_type 3  \n",
       " severity_type 4  severity_type 4  \n",
       " severity_type 5  severity_type 5  }"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>sample</th>\n",
       "      <th>log_feature</th>\n",
       "      <th>volume</th>\n",
       "      <th>severity_type</th>\n",
       "      <th>event_type</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>location_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>log_feature_pchisqr</th>\n",
       "      <th>severity_type_sum</th>\n",
       "      <th>severity_type_std</th>\n",
       "      <th>severity_type_pchisqr</th>\n",
       "      <th>resource_type_sum</th>\n",
       "      <th>resource_type_std</th>\n",
       "      <th>resource_type_pchisqr</th>\n",
       "      <th>event_type_sum</th>\n",
       "      <th>event_type_std</th>\n",
       "      <th>event_type_pchisqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>5320.411116</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.11098</td>\n",
       "      <td>13928.694644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12008</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>5320.411116</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.11098</td>\n",
       "      <td>13928.694644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>18441</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>5320.411116</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.11098</td>\n",
       "      <td>13928.694644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9479</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>5320.411116</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.11098</td>\n",
       "      <td>13928.694644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2627</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>4</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>207</td>\n",
       "      <td>...</td>\n",
       "      <td>5320.411116</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.11098</td>\n",
       "      <td>13928.694644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fault_severity     id      location sample  log_feature volume  \\\n",
       "0               1  14121  location 118  train  feature 312      4   \n",
       "1               0  12008  location 118  train  feature 312      4   \n",
       "2               0  18441  location 118  train  feature 312      4   \n",
       "3               0   9479  location 118  train  feature 312      4   \n",
       "4               0   2627  location 118  train  feature 312      4   \n",
       "\n",
       "     severity_type     event_type    resource_type  location_sum  \\\n",
       "0  severity_type 2  event_type 34  resource_type 2           207   \n",
       "1  severity_type 2  event_type 34  resource_type 2           207   \n",
       "2  severity_type 2  event_type 34  resource_type 2           207   \n",
       "3  severity_type 2  event_type 34  resource_type 2           207   \n",
       "4  severity_type 2  event_type 34  resource_type 2           207   \n",
       "\n",
       "          ...          log_feature_pchisqr  severity_type_sum  \\\n",
       "0         ...                  5320.411116              24260   \n",
       "1         ...                  5320.411116              24260   \n",
       "2         ...                  5320.411116              24260   \n",
       "3         ...                  5320.411116              24260   \n",
       "4         ...                  5320.411116              24260   \n",
       "\n",
       "   severity_type_std  severity_type_pchisqr  resource_type_sum  \\\n",
       "0        9922.367728            24349.55845              31746   \n",
       "1        9922.367728            24349.55845              31746   \n",
       "2        9922.367728            24349.55845              31746   \n",
       "3        9922.367728            24349.55845              31746   \n",
       "4        9922.367728            24349.55845              31746   \n",
       "\n",
       "   resource_type_std  resource_type_pchisqr  event_type_sum  event_type_std  \\\n",
       "0       11667.207935           25727.412776           11390      5142.11098   \n",
       "1       11667.207935           25727.412776           11390      5142.11098   \n",
       "2       11667.207935           25727.412776           11390      5142.11098   \n",
       "3       11667.207935           25727.412776           11390      5142.11098   \n",
       "4       11667.207935           25727.412776           11390      5142.11098   \n",
       "\n",
       "   event_type_pchisqr  \n",
       "0        13928.694644  \n",
       "1        13928.694644  \n",
       "2        13928.694644  \n",
       "3        13928.694644  \n",
       "4        13928.694644  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_sum</th>\n",
       "      <th>location_std</th>\n",
       "      <th>location_pchisqr</th>\n",
       "      <th>log_feature_sum</th>\n",
       "      <th>log_feature_std</th>\n",
       "      <th>log_feature_pchisqr</th>\n",
       "      <th>severity_type_sum</th>\n",
       "      <th>severity_type_std</th>\n",
       "      <th>severity_type_pchisqr</th>\n",
       "      <th>resource_type_sum</th>\n",
       "      <th>resource_type_std</th>\n",
       "      <th>resource_type_pchisqr</th>\n",
       "      <th>event_type_sum</th>\n",
       "      <th>event_type_std</th>\n",
       "      <th>event_type_pchisqr</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207</td>\n",
       "      <td>109.284034</td>\n",
       "      <td>346.173913</td>\n",
       "      <td>4534</td>\n",
       "      <td>2005.107811</td>\n",
       "      <td>5320.411116</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.110980</td>\n",
       "      <td>13928.694644</td>\n",
       "      <td>14121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207</td>\n",
       "      <td>109.284034</td>\n",
       "      <td>346.173913</td>\n",
       "      <td>4534</td>\n",
       "      <td>2005.107811</td>\n",
       "      <td>5320.411116</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11989</td>\n",
       "      <td>5433.055341</td>\n",
       "      <td>14772.586704</td>\n",
       "      <td>14121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207</td>\n",
       "      <td>109.284034</td>\n",
       "      <td>346.173913</td>\n",
       "      <td>4200</td>\n",
       "      <td>1839.960869</td>\n",
       "      <td>4836.365714</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.110980</td>\n",
       "      <td>13928.694644</td>\n",
       "      <td>14121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207</td>\n",
       "      <td>109.284034</td>\n",
       "      <td>346.173913</td>\n",
       "      <td>4200</td>\n",
       "      <td>1839.960869</td>\n",
       "      <td>4836.365714</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11989</td>\n",
       "      <td>5433.055341</td>\n",
       "      <td>14772.586704</td>\n",
       "      <td>14121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408</td>\n",
       "      <td>203.538694</td>\n",
       "      <td>609.235294</td>\n",
       "      <td>1249</td>\n",
       "      <td>669.821120</td>\n",
       "      <td>2155.293835</td>\n",
       "      <td>24260</td>\n",
       "      <td>9922.367728</td>\n",
       "      <td>24349.55845</td>\n",
       "      <td>31746</td>\n",
       "      <td>11667.207935</td>\n",
       "      <td>25727.412776</td>\n",
       "      <td>11390</td>\n",
       "      <td>5142.110980</td>\n",
       "      <td>13928.694644</td>\n",
       "      <td>9320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_sum  location_std  location_pchisqr  log_feature_sum  \\\n",
       "0           207    109.284034        346.173913             4534   \n",
       "1           207    109.284034        346.173913             4534   \n",
       "2           207    109.284034        346.173913             4200   \n",
       "3           207    109.284034        346.173913             4200   \n",
       "4           408    203.538694        609.235294             1249   \n",
       "\n",
       "   log_feature_std  log_feature_pchisqr  severity_type_sum  severity_type_std  \\\n",
       "0      2005.107811          5320.411116              24260        9922.367728   \n",
       "1      2005.107811          5320.411116              24260        9922.367728   \n",
       "2      1839.960869          4836.365714              24260        9922.367728   \n",
       "3      1839.960869          4836.365714              24260        9922.367728   \n",
       "4       669.821120          2155.293835              24260        9922.367728   \n",
       "\n",
       "   severity_type_pchisqr  resource_type_sum  resource_type_std  \\\n",
       "0            24349.55845              31746       11667.207935   \n",
       "1            24349.55845              31746       11667.207935   \n",
       "2            24349.55845              31746       11667.207935   \n",
       "3            24349.55845              31746       11667.207935   \n",
       "4            24349.55845              31746       11667.207935   \n",
       "\n",
       "   resource_type_pchisqr  event_type_sum  event_type_std  event_type_pchisqr  \\\n",
       "0           25727.412776           11390     5142.110980        13928.694644   \n",
       "1           25727.412776           11989     5433.055341        14772.586704   \n",
       "2           25727.412776           11390     5142.110980        13928.694644   \n",
       "3           25727.412776           11989     5433.055341        14772.586704   \n",
       "4           25727.412776           11390     5142.110980        13928.694644   \n",
       "\n",
       "      id  \n",
       "0  14121  \n",
       "1  14121  \n",
       "2  14121  \n",
       "3  14121  \n",
       "4   9320  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats=join.iloc[:,9:]\n",
    "stats['id']=join['id']\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:987: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:965: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/share/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:1011: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_sum</th>\n",
       "      <th>location_std</th>\n",
       "      <th>location_pchisqr</th>\n",
       "      <th>log_feature_sum</th>\n",
       "      <th>log_feature_std</th>\n",
       "      <th>log_feature_pchisqr</th>\n",
       "      <th>severity_type_sum</th>\n",
       "      <th>severity_type_std</th>\n",
       "      <th>severity_type_pchisqr</th>\n",
       "      <th>resource_type_sum</th>\n",
       "      <th>resource_type_std</th>\n",
       "      <th>resource_type_pchisqr</th>\n",
       "      <th>event_type_sum</th>\n",
       "      <th>event_type_std</th>\n",
       "      <th>event_type_pchisqr</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235023</td>\n",
       "      <td>0.083863</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>-0.464502</td>\n",
       "      <td>-0.102130</td>\n",
       "      <td>-0.043944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.592657e-16</td>\n",
       "      <td>-4.242214e-17</td>\n",
       "      <td>-0.744996</td>\n",
       "      <td>-0.101537</td>\n",
       "      <td>-0.026176</td>\n",
       "      <td>-0.676129</td>\n",
       "      <td>-0.172748</td>\n",
       "      <td>-0.049864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198157</td>\n",
       "      <td>0.832327</td>\n",
       "      <td>1.400754</td>\n",
       "      <td>0.318563</td>\n",
       "      <td>1.054778</td>\n",
       "      <td>1.132216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766231</td>\n",
       "      <td>0.947210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.520737</td>\n",
       "      <td>-0.439720</td>\n",
       "      <td>-0.262486</td>\n",
       "      <td>-0.890712</td>\n",
       "      <td>-0.186672</td>\n",
       "      <td>-0.064518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.242214e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.350230</td>\n",
       "      <td>-0.337548</td>\n",
       "      <td>-0.217245</td>\n",
       "      <td>-1.121180</td>\n",
       "      <td>-0.237854</td>\n",
       "      <td>-0.076383</td>\n",
       "      <td>-1.895865</td>\n",
       "      <td>-6.788001e-01</td>\n",
       "      <td>-1.015120e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.996862</td>\n",
       "      <td>-0.396716</td>\n",
       "      <td>-0.110034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.292294</td>\n",
       "      <td>0.245936</td>\n",
       "      <td>1.950529</td>\n",
       "      <td>2.264430</td>\n",
       "      <td>2.052783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766231</td>\n",
       "      <td>0.947210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location_sum  location_std  location_pchisqr  log_feature_sum  \\\n",
       "id                                                                  \n",
       "1       0.235023      0.083863          0.005554        -0.464502   \n",
       "2       0.198157      0.832327          1.400754         0.318563   \n",
       "3      -0.520737     -0.439720         -0.262486        -0.890712   \n",
       "4      -0.350230     -0.337548         -0.217245        -1.121180   \n",
       "5       0.258065      0.292294          0.245936         1.950529   \n",
       "\n",
       "    log_feature_std  log_feature_pchisqr  severity_type_sum  \\\n",
       "id                                                            \n",
       "1         -0.102130            -0.043944           1.000000   \n",
       "2          1.054778             1.132216           0.000000   \n",
       "3         -0.186672            -0.064518           1.000000   \n",
       "4         -0.237854            -0.076383          -1.895865   \n",
       "5          2.264430             2.052783           0.000000   \n",
       "\n",
       "    severity_type_std  severity_type_pchisqr  resource_type_sum  \\\n",
       "id                                                                \n",
       "1       -1.592657e-16          -4.242214e-17          -0.744996   \n",
       "2        1.000000e+00           1.000000e+00           1.000000   \n",
       "3        0.000000e+00          -4.242214e-17           0.000000   \n",
       "4       -6.788001e-01          -1.015120e-01           1.000000   \n",
       "5        1.000000e+00           1.000000e+00           1.000000   \n",
       "\n",
       "    resource_type_std  resource_type_pchisqr  event_type_sum  event_type_std  \\\n",
       "id                                                                             \n",
       "1           -0.101537              -0.026176       -0.676129       -0.172748   \n",
       "2            1.000000               1.000000        0.000000        0.766231   \n",
       "3            0.000000               0.000000        0.247977        0.000000   \n",
       "4            1.000000               1.000000       -1.996862       -0.396716   \n",
       "5            1.000000               1.000000        0.000000        0.766231   \n",
       "\n",
       "    event_type_pchisqr  id  \n",
       "id                          \n",
       "1            -0.049864   1  \n",
       "2             0.947210   2  \n",
       "3             0.000000   3  \n",
       "4            -0.110034   4  \n",
       "5             0.947210   5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats=stats.groupby('id').mean()\n",
    "stats=stats.fillna(value=0)\n",
    "stats['id']=stats.index\n",
    "for column in stats.columns:\n",
    "    if column is not 'id':\n",
    "        stats[column]=pre.robust_scale(stats[column]) #scale all but id\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>location 118</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9320</td>\n",
       "      <td>location 91</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14394</td>\n",
       "      <td>location 152</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8218</td>\n",
       "      <td>location 931</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14804</td>\n",
       "      <td>location 120</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fault_severity     id      location sample\n",
       "0               1  14121  location 118  train\n",
       "1               0   9320   location 91  train\n",
       "2               1  14394  location 152  train\n",
       "3               1   8218  location 931  train\n",
       "4               0  14804  location 120  train"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['stats']=stats\n",
    "join=pd.concat([datasets['train'],datasets['test']],ignore_index=True)\n",
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert table of ids and classes to binary row feature vectors for each unique id\n",
    "for key, dataset in datasets.items():\n",
    "    tmp=pd.get_dummies(dataset,dummy_na=True)\n",
    "    tmp=tmp.groupby('id').sum()\n",
    "    tmp['id']=tmp.index\n",
    "    dataset=tmp\n",
    "    datasets[key]=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#joins features from different datasets into one dataframe, features only for evaluated ids are extracted\n",
    "#(i.e. some features may be not related to any id)\n",
    "samples=['train','test']\n",
    "for key, dataset in datasets.items():\n",
    "    if key not in samples:\n",
    "        join=pd.merge(join,dataset,on='id',how='left')\n",
    "\n",
    "join=pd.merge(join,stats,on='id')\n",
    "join=join.set_index(['sample'])\n",
    "join=pd.get_dummies(join) #fixes dummies for location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>log_feature_feature 1</th>\n",
       "      <th>log_feature_feature 10</th>\n",
       "      <th>log_feature_feature 100</th>\n",
       "      <th>log_feature_feature 101</th>\n",
       "      <th>log_feature_feature 102</th>\n",
       "      <th>log_feature_feature 103</th>\n",
       "      <th>log_feature_feature 104</th>\n",
       "      <th>log_feature_feature 105</th>\n",
       "      <th>...</th>\n",
       "      <th>location_location 990</th>\n",
       "      <th>location_location 991</th>\n",
       "      <th>location_location 992</th>\n",
       "      <th>location_location 993</th>\n",
       "      <th>location_location 994</th>\n",
       "      <th>location_location 995</th>\n",
       "      <th>location_location 996</th>\n",
       "      <th>location_location 997</th>\n",
       "      <th>location_location 998</th>\n",
       "      <th>location_location 999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0</td>\n",
       "      <td>9320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1</td>\n",
       "      <td>14394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1</td>\n",
       "      <td>8218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0</td>\n",
       "      <td>14804</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1621 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fault_severity     id  log_feature_feature 1  log_feature_feature 10  \\\n",
       "sample                                                                         \n",
       "train                1  14121                      0                       0   \n",
       "train                0   9320                      0                       0   \n",
       "train                1  14394                      0                       0   \n",
       "train                1   8218                      0                       0   \n",
       "train                0  14804                      0                       0   \n",
       "\n",
       "        log_feature_feature 100  log_feature_feature 101  \\\n",
       "sample                                                     \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "\n",
       "        log_feature_feature 102  log_feature_feature 103  \\\n",
       "sample                                                     \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "\n",
       "        log_feature_feature 104  log_feature_feature 105  \\\n",
       "sample                                                     \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "train                         0                        0   \n",
       "\n",
       "                ...            location_location 990  location_location 991  \\\n",
       "sample          ...                                                           \n",
       "train           ...                                0                      0   \n",
       "train           ...                                0                      0   \n",
       "train           ...                                0                      0   \n",
       "train           ...                                0                      0   \n",
       "train           ...                                0                      0   \n",
       "\n",
       "        location_location 992  location_location 993  location_location 994  \\\n",
       "sample                                                                        \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "\n",
       "        location_location 995  location_location 996  location_location 997  \\\n",
       "sample                                                                        \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "\n",
       "        location_location 998  location_location 999  \n",
       "sample                                                \n",
       "train                       0                      0  \n",
       "train                       0                      0  \n",
       "train                       0                      0  \n",
       "train                       0                      0  \n",
       "train                       0                      0  \n",
       "\n",
       "[5 rows x 1621 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalizes a continuous feature\n",
    "#join['volume']=pre.minmax_scale(join['volume'].astype(float))\n",
    "\n",
    "#fills in missing data\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n",
    "join = DataFrameImputer().fit_transform(join)\n",
    "#join=join.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 4520, cost: 167141.0\n",
      "Run 1, iteration: 2/100, moves: 3732, cost: 163281.0\n",
      "Run 1, iteration: 3/100, moves: 905, cost: 163281.0\n"
     ]
    }
   ],
   "source": [
    "from kmodes import kmodes\n",
    "\n",
    "km = kmodes.KModes(n_clusters=5, init='Huang', n_init=1, verbose=1)\n",
    "clusters = km.fit_predict(join[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>sum</th>\n",
       "      <th>volume</th>\n",
       "      <th>log_feature_feature 1</th>\n",
       "      <th>log_feature_feature 10</th>\n",
       "      <th>log_feature_feature 100</th>\n",
       "      <th>...</th>\n",
       "      <th>location_location 995</th>\n",
       "      <th>location_location 996</th>\n",
       "      <th>location_location 997</th>\n",
       "      <th>location_location 998</th>\n",
       "      <th>location_location 999</th>\n",
       "      <th>cluster_0</th>\n",
       "      <th>cluster_1</th>\n",
       "      <th>cluster_2</th>\n",
       "      <th>cluster_3</th>\n",
       "      <th>cluster_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>0.094788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0</td>\n",
       "      <td>9320</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49</td>\n",
       "      <td>3.670196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1</td>\n",
       "      <td>14394</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.368214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1</td>\n",
       "      <td>8218</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.110991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0</td>\n",
       "      <td>14804</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.239603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fault_severity     id        p0        p1        p2  sum    volume  \\\n",
       "sample                                                                       \n",
       "train                1  14121  0.909091  0.090909  0.000000   33  0.094788   \n",
       "train                0   9320  0.897959  0.102041  0.000000   49  3.670196   \n",
       "train                1  14394  0.600000  0.400000  0.000000    5 -0.368214   \n",
       "train                1   8218  0.696970  0.181818  0.121212   33 -0.110991   \n",
       "train                0  14804  0.500000  0.500000  0.000000   12 -0.239603   \n",
       "\n",
       "        log_feature_feature 1  log_feature_feature 10  \\\n",
       "sample                                                  \n",
       "train                       0                       0   \n",
       "train                       0                       0   \n",
       "train                       0                       0   \n",
       "train                       0                       0   \n",
       "train                       0                       0   \n",
       "\n",
       "        log_feature_feature 100    ...      location_location 995  \\\n",
       "sample                             ...                              \n",
       "train                         0    ...                          0   \n",
       "train                         0    ...                          0   \n",
       "train                         0    ...                          0   \n",
       "train                         0    ...                          0   \n",
       "train                         0    ...                          0   \n",
       "\n",
       "        location_location 996  location_location 997  location_location 998  \\\n",
       "sample                                                                        \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "train                       0                      0                      0   \n",
       "\n",
       "        location_location 999  cluster_0  cluster_1  cluster_2  cluster_3  \\\n",
       "sample                                                                      \n",
       "train                       0          0          0          1          0   \n",
       "train                       0          0          0          1          0   \n",
       "train                       0          0          0          1          0   \n",
       "train                       0          0          0          0          0   \n",
       "train                       0          0          0          0          0   \n",
       "\n",
       "        cluster_4  \n",
       "sample             \n",
       "train           0  \n",
       "train           0  \n",
       "train           0  \n",
       "train           1  \n",
       "train           1  \n",
       "\n",
       "[5 rows x 1596 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join['clusters']=clusters\n",
    "join=pd.concat([join,pd.get_dummies(join['clusters'],prefix='cluster')],axis=1)\n",
    "del join['clusters']\n",
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creates features and targets for final training\n",
    "features=join.columns.values.tolist()\n",
    "not_features=['fault_severity', 'id'] #not_features=['fault_severity', 'id'] \n",
    "for x in features:\n",
    "    if \"_nan\" in x:\n",
    "        features.remove(x)\n",
    "        not_features.append(x)\n",
    "        \n",
    "for x in not_features:\n",
    "    if x in features:\n",
    "        features.remove(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = join.loc['train'][features]\n",
    "train_target = join.loc['train']['fault_severity']\n",
    "\n",
    "test_features = join.loc['test'][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "sz=(train_features.values).shape\n",
    "\n",
    "train_X = train_features.values[:int(sz[0] * 0.7), :]\n",
    "train_Y = train_target.values[:int(sz[0]*0.7)]\n",
    "#wtr = join.loc['train']['sum'].values[:int(sz[0]*0.7)]\n",
    "\n",
    "\n",
    "test_X = train_features.values[int(sz[0] * 0.7):, :]\n",
    "test_Y = train_target.values[int(sz[0] * 0.7):]\n",
    "#wte = join.loc['train']['sum'].values[int(sz[0] * 0.7):]\n",
    "\n",
    "xg_train = xgb.DMatrix(train_X, label=train_Y,feature_names=train_features.columns) #\n",
    "#xg_train.set_weight(wtr)\n",
    "full_xg_train = xgb.DMatrix(train_features, label=train_target.values,feature_names=train_features.columns) #\n",
    "\n",
    "xg_test = xgb.DMatrix(test_X, label=test_Y,feature_names=test_features.columns) #\n",
    "#xg_test.set_weight(wte)\n",
    "full_xg_test = xgb.DMatrix(test_features,feature_names=test_features.columns) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.621968\ttest-mlogloss:0.672761\n",
      "[1]\ttrain-mlogloss:0.531834\ttest-mlogloss:0.607101\n",
      "[2]\ttrain-mlogloss:0.504729\ttest-mlogloss:0.589246\n",
      "[3]\ttrain-mlogloss:0.492034\ttest-mlogloss:0.578604\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.675589</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.621989</td>\n",
       "      <td>0.005857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.610774</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.535966</td>\n",
       "      <td>0.006149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.590008</td>\n",
       "      <td>0.016091</td>\n",
       "      <td>0.503040</td>\n",
       "      <td>0.003222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.582110</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>0.482687</td>\n",
       "      <td>0.003750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-mlogloss-mean  test-mlogloss-std  train-mlogloss-mean  \\\n",
       "0            0.675589           0.009442             0.621989   \n",
       "1            0.610774           0.012241             0.535966   \n",
       "2            0.590008           0.016091             0.503040   \n",
       "3            0.582110           0.016329             0.482687   \n",
       "\n",
       "   train-mlogloss-std  \n",
       "0            0.005857  \n",
       "1            0.006149  \n",
       "2            0.003222  \n",
       "3            0.003750  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softprob'\n",
    "param['eta'] = 1\n",
    "param['gamma']= 4\n",
    "param['max_depth'] = 15\n",
    "param['min_child_weight']=4\n",
    "param['max_delta_step']=4\n",
    "\n",
    "param['nthread'] = 3\n",
    "#param['subsample']=1\n",
    "param['num_class'] = 3\n",
    "param['eval_metric']='mlogloss'\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 4\n",
    "bst = xgb.train(param, xg_train,num_round,evals=watchlist);\n",
    "# get prediction\n",
    "pred = bst.predict( xg_test );\n",
    "\n",
    "xgb.cv(param, xg_train, num_round, nfold=3,\n",
    "       metrics=['mlogloss'], seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(booster=bst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.618051\ttest-mlogloss:0.613721\n",
      "[1]\ttrain-mlogloss:0.543451\ttest-mlogloss:0.536194\n",
      "[2]\ttrain-mlogloss:0.515183\ttest-mlogloss:0.510487\n",
      "[3]\ttrain-mlogloss:0.492402\ttest-mlogloss:0.489787\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668221</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>0.010597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603008</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.559228</td>\n",
       "      <td>0.007504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.581622</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.532272</td>\n",
       "      <td>0.006528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.570103</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>0.511354</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-mlogloss-mean  test-mlogloss-std  train-mlogloss-mean  \\\n",
       "0            0.668221           0.006264             0.633977   \n",
       "1            0.603008           0.012130             0.559228   \n",
       "2            0.581622           0.013304             0.532272   \n",
       "3            0.570103           0.013579             0.511354   \n",
       "\n",
       "   train-mlogloss-std  \n",
       "0            0.010597  \n",
       "1            0.007504  \n",
       "2            0.006528  \n",
       "3            0.008957  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst=xgb.train(param, full_xg_train, num_round,evals=watchlist)\n",
    "test_response=bst.predict(full_xg_test)\n",
    "xgb.cv(param, xg_train, num_round, nfold=3,\n",
    "       metrics=['mlogloss'], seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  0., ...,  1.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save predictions to required format \n",
    "#make it binary?\n",
    "out=pd.DataFrame({'id':[],'predict_0':[],'predict_1':[],'predict_2':[]})\n",
    "out['id']=join.loc['test']['id']\n",
    "out['predict_0']=test_response.T[0]\n",
    "out['predict_1']=test_response.T[1]\n",
    "out['predict_2']=test_response.T[2]\n",
    "out=out[['id','predict_0','predict_1','predict_2']]\n",
    "out.to_csv('predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in join.columns:\n",
    "    if column not in ['id','fault_severity']:\n",
    "        join[column]=join[column].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifierCV, Perceptron, SGDClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import log_loss, accuracy_score, classification_report\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier, OutputCodeClassifier\n",
    "from sklearn import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train_features, train_target, test_size=0.31, random_state=0)\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = t.time()\n",
    "    #clf=OneVsRestClassifier(clf) #may want to remove for testing\n",
    "    clf.fit(train_x, train_y)\n",
    "    train_time = t.time() - t0\n",
    "    print(\"Training time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = t.time()\n",
    "    y_pred_single = clf.predict(test_x)\n",
    "    if (hasattr(clf,'predict_proba')):\n",
    "        y_pred_dist = clf.predict_proba(test_x)\n",
    "        logloss=log_loss(test_y,y_pred_dist)\n",
    "        print(\"LogLoss: %0.3fs\" % logloss)\n",
    "    test_time = t.time() - t0\n",
    "    print(\"Prediction time:  %0.3fs\" % test_time)\n",
    "\n",
    "    acc_score = accuracy_score(test_y, y_pred_single)\n",
    "    print(\"Accuracy:   %0.3f\" % acc_score)\n",
    "    \n",
    "    #if (hasattr(clf,'predict_proba')):\n",
    "       #scores = cross_val_score(clf,train_features,train_target, scoring='log_loss')\n",
    "        #loss_score=scores.mean()\n",
    "        #print(\"CV LogLoss: %0.2f (+/- %0.2f)\" % (loss_score, scores.std() * 2))\n",
    "    \n",
    "    print(classification_report(test_y, y_pred_single))\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    \n",
    "    if (hasattr(clf,'predict_proba')):\n",
    "        return clf_descr, acc_score, logloss, train_time, test_time\n",
    "    else:\n",
    "        return clf_descr, acc_score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifierCV(alphas=(0.1, 1.0, 10.0), class_weight=None, cv=None,\n",
      "         fit_intercept=True, normalize=False, scoring=None)\n",
      "Training time: 4.643s\n",
      "Prediction time:  0.038s\n",
      "Accuracy:   0.727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.91      0.84      1476\n",
      "        1.0       0.59      0.35      0.44       593\n",
      "        2.0       0.49      0.55      0.52       220\n",
      "\n",
      "avg / total       0.71      0.73      0.71      2289\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Training time: 17.260s\n",
      "Prediction time:  0.930s\n",
      "Accuracy:   0.736\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.88      0.84      1476\n",
      "        1.0       0.59      0.47      0.52       593\n",
      "        2.0       0.54      0.49      0.51       220\n",
      "\n",
      "avg / total       0.72      0.74      0.73      2289\n",
      "\n",
      "================================================================================\n",
      "AdaBoost\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Training time: 2.913s\n",
      "Prediction time:  0.465s\n",
      "Accuracy:   0.720\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.90      0.83      1476\n",
      "        1.0       0.58      0.31      0.40       593\n",
      "        2.0       0.54      0.62      0.58       220\n",
      "\n",
      "avg / total       0.70      0.72      0.70      2289\n",
      "\n",
      "================================================================================\n",
      "Bagging\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "Training time: 3.196s\n",
      "Prediction time:  0.596s\n",
      "Accuracy:   0.730\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.87      0.83      1476\n",
      "        1.0       0.59      0.47      0.52       593\n",
      "        2.0       0.55      0.49      0.52       220\n",
      "\n",
      "avg / total       0.72      0.73      0.72      2289\n",
      "\n",
      "================================================================================\n",
      "DiscriminatnAnalysis\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "Training time: 5.013s\n",
      "Prediction time:  1.510s\n",
      "Accuracy:   0.603\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.76      0.73      1476\n",
      "        1.0       0.44      0.40      0.42       593\n",
      "        2.0       0.09      0.07      0.08       220\n",
      "\n",
      "avg / total       0.58      0.60      0.59      2289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:688: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifierCV(), \"Ridge Classifier\"),\n",
    "        (RandomForestClassifier(n_estimators=300), \"Random forest\"),\n",
    "        (AdaBoostClassifier(), \"AdaBoost\"),\n",
    "        (BaggingClassifier(), \"Bagging\"),\n",
    "        (QuadraticDiscriminantAnalysis(), \"DiscriminatnAnalysis\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "OneVsRestClassifier(estimator=GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=200, presort=True,\n",
      "              random_state=None, subsample=1.0, verbose=1,\n",
      "              warm_start=False),\n",
      "          n_jobs=-2)\n",
      "Training time: 92.315s\n",
      "Prediction time:  0.573s\n",
      "Accuracy:   0.739\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.89      0.84      1476\n",
      "        1.0       0.61      0.42      0.50       593\n",
      "        2.0       0.55      0.60      0.58       220\n",
      "\n",
      "avg / total       0.73      0.74      0.73      2289\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('OneVsRestClassifier',\n",
       " 0.73918741808650068,\n",
       " 0.57045593736126277,\n",
       " 92.31480956077576,\n",
       " 0.5728719234466553)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test a classifier\n",
    "\n",
    "# Fit the model to training data\n",
    "#parameters={'n_estimators':[100,150]},'max_depth':[3]}\n",
    "clf = OneVsRestClassifier(GradientBoostingClassifier(n_estimators=200,verbose=1,presort=True,max_depth=7),n_jobs=-2)#,min_samples_leaf=10,min_samples_split=5)\n",
    "#clf=grid_search.GridSearchCV(gbc, parameters,n_jobs=-2)\n",
    "benchmark(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=-2,\n",
      "            oob_score=True, random_state=None, verbose=1, warm_start=False),\n",
      "          n_jobs=-2)\n",
      "Training time: 31.099s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 400 out of 400 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction time:  1.980s\n",
      "Accuracy:   0.751\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.90      0.85      1476\n",
      "        1.0       0.63      0.44      0.52       593\n",
      "        2.0       0.59      0.56      0.57       220\n",
      "\n",
      "avg / total       0.74      0.75      0.74      2289\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('OneVsRestClassifier',\n",
       " 0.75141983398864132,\n",
       " 0.54245802948043198,\n",
       " 31.099143743515015,\n",
       " 1.9801154136657715)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test a classifier\n",
    "\n",
    "# Fit the model to training data\n",
    "#parameters={'n_estimators':[100,150]},'max_depth':[3]}\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=400,verbose=1,min_samples_split=10,\\\n",
    "                                                 oob_score=True,n_jobs=-2),n_jobs=-2)\n",
    "#clf=grid_search.GridSearchCV(gbc, parameters,n_jobs=-2)\n",
    "benchmark(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: -0.56 (+/- 0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   3 out of   3 | elapsed:   44.6s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf,train_features,train_target, scoring='log_loss',n_jobs=-2,verbose=True)\n",
    "print(\"LogLoss: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestCLF=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-2)]: Done 400 out of 400 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=800,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=-2,\n",
       "            oob_score=True, random_state=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestCLF.fit(train_features,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=3)]: Done 400 out of 400 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "test_response=bestCLF.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>event_type</th>\n",
       "      <th>severity_type</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>log_feature</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">train</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>148</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>148</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>148</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>148</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9320</td>\n",
       "      <td>1027</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fault_severity     id  location  event_type  severity_type  \\\n",
       "sample                                                                 \n",
       "train  0               1  14121       148          26              1   \n",
       "       1               1  14121       148          26              1   \n",
       "       2               1  14121       148          27              1   \n",
       "       3               1  14121       148          27              1   \n",
       "       4               0   9320      1027          26              1   \n",
       "\n",
       "          resource_type  log_feature  volume  \n",
       "sample                                        \n",
       "train  0              2          237      19  \n",
       "       1              2          148      19  \n",
       "       2              2          237      19  \n",
       "       3              2          148      19  \n",
       "       4              2          240     200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform cat labels into digits\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for column in join.columns:\n",
    "    if column not in notCat:\n",
    "        join[column]=le.fit_transform(join[column])\n",
    "    \n",
    "join.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
